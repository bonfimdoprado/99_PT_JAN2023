{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPk-p3YAwRp1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLWfXX-9wRp4"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/pedroteche-ih/DAFT_MEX_202209/main/data/tb_ames_housing.csv\"\n",
    "tb_housing = pd.read_csv(url)\n",
    "clu_vars = [\n",
    "    \"LotFrontage\",\n",
    "    \"LotArea\",\n",
    "    \"OverallQual\",\n",
    "    \"OverallCond\",\n",
    "    \"MasVnrArea\",\n",
    "    \"BsmtFinSF1\",\n",
    "    \"BsmtFinSF2\",\n",
    "    \"BsmtUnfSF\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"1stFlrSF\",\n",
    "    \"2ndFlrSF\",\n",
    "    \"LowQualFinSF\",\n",
    "    \"GrLivArea\",\n",
    "    \"BsmtFullBath\",\n",
    "    \"BsmtHalfBath\",\n",
    "    \"FullBath\",\n",
    "    \"HalfBath\",\n",
    "    \"BedroomAbvGr\",\n",
    "    \"KitchenAbvGr\",\n",
    "    \"TotRmsAbvGrd\",\n",
    "    \"Fireplaces\",\n",
    "    \"GarageCars\",\n",
    "    \"GarageArea\",\n",
    "    \"WoodDeckSF\",\n",
    "    \"OpenPorchSF\",\n",
    "    \"EnclosedPorch\",\n",
    "    \"3SsnPorch\",\n",
    "    \"ScreenPorch\",\n",
    "    \"PoolArea\",\n",
    "    \"MiscVal\"\n",
    "]\n",
    "tb_housing = tb_housing.dropna(subset=clu_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizando Estrutura de Correlação\n",
    "\n",
    "Até agora vimos duas formas de tratar colinearidade: através da seleção manual de variáveis utilizando a matriz de correlação e utilizando PCA. Hoje veremos mais técnicas exploratórias para visualizar nosso espaço de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(tb_housing[clu_vars].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiAjfmD2wRp4"
   },
   "source": [
    "# Utilizando HACs\n",
    "\n",
    "Como vimos na aula passada, HACs são ferramentas poderosas que nos permitem agrupar de forma hierarquica as observações de um dataset. HACs tem uma limitação: não escalam bem conforme **aumentamos o número de pontos em um dataset**.\n",
    "\n",
    "Para utilizar um HAC para clusterizar nossas variáveis basta perceber que se **transpormos** nossa matriz de dados nossas *observações serão nossas variáveis!* Além de permitir clusterizar nossas variáveis, isto contorna a principal limitação dos HACs: mesmo que nosso dataset contenha centena de *features* não teremos problemas com limitações de memória e processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-w775AzwRp7"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "tb_sca_housing_num = scaler.fit_transform(tb_housing[clu_vars])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdQHJ6ZD6kVI"
   },
   "outputs": [],
   "source": [
    "tb_sca_housing_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poddemos usar o atributo `.T` para acessar a matriz transposta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnliN9hnwRp7"
   },
   "outputs": [],
   "source": [
    "tb_sca_housing_num.T.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma consideração importante a se fazer quando agrupamos variáveis utilizando um HAC é a definição da distância: embora a distância euclideana seja suficiente para maior parte dos problemas ela não é uma boa função de distância para medir semelhança entre variáveis.\n",
    "\n",
    "Uma medida que já aprendemos nos permite estimar bem esta semelhança: a distância de correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LO6N6IHfwRp7"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "link = linkage(tb_sca_housing_num.T, method=\"complete\", metric=\"cosine\")\n",
    "housing_dendogram = dendrogram(link, labels=scaler.feature_names_in_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos investigar a matriz de correlação do primeiro grupo de variáveis (à distância 0.8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZN_y_k7wRp8"
   },
   "outputs": [],
   "source": [
    "clu_0 = [\n",
    "    \"FullBath\",\n",
    "    \"BedroomAbvGr\",\n",
    "    \"2ndFlrSF\",\n",
    "    \"GrLivArea\",\n",
    "    \"TotRmsAbvGrd\",\n",
    "    \"HalfBath\",\n",
    "    \"OpenPorchSF\",\n",
    "]\n",
    "sns.heatmap(tb_housing[clu_0].corr(), vmin=-1, center=0, vmax=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta técnica de agrupamento de features é muito utilizada como **ferramenta exploratória**, complementar a utilização da matriz de correlação. Mesmo assim, podemos utilizar a função `FeatureAgglomeration` para calcular uma transformação a partir dos agrupamentos estimados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BkEVsZWwRp6"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import FeatureAgglomeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnSPyh-awRp8"
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "var_fit = FeatureAgglomeration(n_clusters=n, affinity='cosine', linkage='complete')\n",
    "var_fit.fit(tb_sca_housing_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUnjhQDKwRp8"
   },
   "outputs": [],
   "source": [
    "tb_var_cluster = pd.DataFrame(\n",
    "    var_fit.transform(tb_sca_housing_num), \n",
    "    columns=[\"CLU_\" + str(i) for i in range(n)]\n",
    ")\n",
    "tb_var_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZW_0OvHwRp8"
   },
   "source": [
    "# Multi-Dimensional Scaling (MDS)\n",
    "\n",
    "A primeira técnica não-supervisionada que aprendemos foi PCA - uma técnica que busca uma **projeção** de nossos dados em um espaço dimensional reduzido, eliminando colinearidades. Uma das limitações de PCA é que reduzimos apenas relações lineares: se duas variáveis tem uma relação não-linear, PCA não irá capturar este padrão.\n",
    "\n",
    "Nesses casos podemos utilizar outra técnica exploratória: **MDS**. MDS (*multi-dimensional scaling*) é uma técnica semelhante à PCA mas que utiliza a proximidade entre observações para criar uma mapa de dimensionalidade reduzida. Podemos pensar nesta operação como a criação de um mapa mundi a partir de um globo: reduzimos as dimensões de nosso dataset enquanto tentamos manter as *similaridades locais* do espaço original.\n",
    "\n",
    "## Utilizando MDS para Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NB11w5kOwRp9"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/pedroteche-ih/DAFT_MEX_202209/main/data/tb_household_electricity.csv'\n",
    "tb_house = pd.read_csv(url, parse_dates = ['date_time'])\n",
    "tb_house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_house = tb_house.sample(1000, random_state=42).copy()\n",
    "tb_house = tb_house.drop('date_time', axis = 1)\n",
    "clu_vars_h = ['sub_metering_1', 'sub_metering_2', 'sub_metering_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(tb_house[clu_vars_h])\n",
    "tb_sca_cp = pd.DataFrame(\n",
    "    scaler.transform(tb_house[clu_vars_h]),\n",
    "    columns = scaler.feature_names_in_\n",
    ")\n",
    "\n",
    "tb_sca_cp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(tb_sca_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMDfqVeswRp9"
   },
   "outputs": [],
   "source": [
    "mds_fit = MDS(n_components=2, random_state = 42)\n",
    "mds_array = mds_fit.fit_transform(tb_sca_cp)\n",
    "\n",
    "tb_mca_house = pd.DataFrame(\n",
    "    mds_array,\n",
    "    columns = ['MC_0', 'MC_1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "90OpxW3IwRp9",
    "outputId": "7cf3b81f-e454-46f5-847e-7fd43d6a0f30"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (10,10))\n",
    "sns.scatterplot(data = tb_mca_house, x = 'MC_0', y = 'MC_1', color = 'red', alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fit = KMeans(n_clusters = 7)\n",
    "k_fit.fit(tb_sca_cp)\n",
    "tb_mca_house['k_cluster'] = [str(x) for x in k_fit.labels_]\n",
    "sns.scatterplot(data = tb_mca_house, x = 'MC_0', y = 'MC_1', hue = 'k_cluster', palette='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HHdVpDQwRqA"
   },
   "outputs": [],
   "source": [
    "tb_sca_cp['k_cluster'] = tb_mca_house['k_cluster']\n",
    "tb_house_melt = tb_sca_cp.melt(id_vars = ['k_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "id": "3ISiohLNwRqA",
    "outputId": "b107679b-9ca5-4fa9-8cab-0bce3b1012d1"
   },
   "outputs": [],
   "source": [
    "sns.catplot(data = tb_house_melt, x = 'k_cluster', y = 'value', col= 'variable', kind = 'bar', col_wrap = 3, palette = 'Spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAL2wyCRwRqA"
   },
   "source": [
    "# UMAP\n",
    "\n",
    "**UMAP** (*Uniform Manifold Approximation and Projection*) é uma técnica de redução de dimensionalidade utilizada para visualizar dados de alta dimensão em um espaço de dimensão inferior. Foi introduzida em 2018 por Leland McInnes, John Healy e James Melville.\n",
    "\n",
    "O UMAP é particularmente eficaz em preservar tanto a **estrutura global** quanto **local** dos dados, tornando-se uma ferramenta poderosa para *análise exploratória de dados* e *visualização*. Ao contrário de métodos tradicionais, como **Análise de Componentes Principais (PCA)** ou **t-SNE (t-Distributed Stochastic Neighbor Embedding)**, o UMAP é baseado em uma estrutura matemática diferente chamada **geometria Riemanniana**.\n",
    "\n",
    "O algoritmo por trás do UMAP envolve a construção de uma representação topológica difusa dos dados de alta dimensão, que captura as relações e similaridades entre os pontos de dados. Essa representação é então otimizada para encontrar uma *incorporação de baixa dimensão* que preserve a estrutura local e global dos dados originais.\n",
    "\n",
    "Uma vantagem notável do UMAP é sua escalabilidade. Ele pode lidar com conjuntos de dados grandes, com milhões de pontos de dados e espaços de recursos de alta dimensão. Além disso, o UMAP permite *exploração interativa*, fornecendo atualizações em tempo real à medida que o usuário ajusta parâmetros ou interage com a visualização.\n",
    "\n",
    "O UMAP tem ganhado popularidade em várias áreas, incluindo biologia, genômica, análise de imagens e processamento de linguagem natural. Ele tem se mostrado útil em tarefas como *análise de agrupamento*, *detecção de anomalias* e *extração de características*, permitindo que pesquisadores e cientistas de dados obtenham insights de dados complexos e de alta dimensão.\n",
    "\n",
    "Em resumo, o UMAP oferece uma abordagem versátil e eficiente para redução de dimensionalidade, fornecendo uma ferramenta valiosa para visualizar e analisar conjuntos de dados complexos, ao mesmo tempo em que preserva informações estruturais importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4LN0yhGwRqB"
   },
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_revenda = pd.read_csv(\"data/tb_revenda.csv\")\n",
    "tb_revenda['categoria_produto'] = tb_revenda['categoria_produto'].astype(str).map(lambda cat: cat.lower())\n",
    "tb_cliente_produto = pd.crosstab(\n",
    "    tb_revenda[\"cd_cliente\"],\n",
    "    tb_revenda[\"categoria_produto\"],\n",
    "    values=tb_revenda[\"receita_bruta\"],\n",
    "    aggfunc=\"sum\",\n",
    "    normalize=\"index\",\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tb_cliente_produto)\n",
    "tb_sca_cp = pd.DataFrame(\n",
    "    scaler.transform(tb_cliente_produto), columns=tb_cliente_produto.columns, index = tb_cliente_produto.index\n",
    ")\n",
    "tb_sca_cp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_fit_5 = umap.UMAP(n_neighbors = 5, n_components=2, random_state=42)\n",
    "umap_fit_5.fit(tb_sca_cp)\n",
    "\n",
    "umap_fit_20 = umap.UMAP(n_neighbors = 20, n_components=2, random_state=42)\n",
    "umap_fit_20.fit(tb_sca_cp)\n",
    "\n",
    "umap_fit_50 = umap.UMAP(n_neighbors = 50, n_components=2, random_state=42)\n",
    "umap_fit_50.fit(tb_sca_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_umap_5 = pd.DataFrame(\n",
    "    umap_fit_5.transform(tb_sca_cp),\n",
    "    columns=[\"UM_0\", \"UM_1\"],\n",
    "    index = tb_sca_cp.index\n",
    ")\n",
    "tb_umap_20 = pd.DataFrame(\n",
    "    umap_fit_20.transform(tb_sca_cp),\n",
    "    columns=[\"UM_0\", \"UM_1\"],\n",
    "    index = tb_sca_cp.index\n",
    ")\n",
    "\n",
    "tb_umap_50 = pd.DataFrame(\n",
    "    umap_fit_50.transform(tb_sca_cp),\n",
    "    columns=[\"UM_0\", \"UM_1\"],\n",
    "    index = tb_sca_cp.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "sns.scatterplot(data=tb_umap_5, x=\"UM_0\", y=\"UM_1\", s = 10, ax = ax[0])\n",
    "ax[0].set_title(\"UMAP with 5 Neighbors\")\n",
    "sns.scatterplot(data=tb_umap_20, x=\"UM_0\", y=\"UM_1\", s = 10, ax = ax[1])\n",
    "ax[1].set_title(\"UMAP with 20 Neighbors\")\n",
    "sns.scatterplot(data=tb_umap_50, x=\"UM_0\", y=\"UM_1\", s = 10, ax = ax[2])\n",
    "ax[2].set_title(\"UMAP with 50 Neighbors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os mapeamentos UMAP podem ser utilizados como pré-processamento tanto em modelos preditivos (para criar novos features) quanto como técnica de visualização. Sua utilização para clusterização é mais limitada, podemos utiliza-lá como ferramenta exploratória mas devemos tomar cuidado com qualquer clusterização que realizarmos sobre os componentes. Uma das principais razões para isso é que o UMAP não preserva a **densidade** no espaço de features. Podemos utilizar o argumento `densmap = True` para contornar parcialmente esse problema, mas ainda assim, sempre que possível, devemos utilizar o UMAP como ferramenta exploratória em problemas não supervisionados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_fit_5 = umap.UMAP(n_neighbors = 5, n_components=2, random_state=42, densmap = True)\n",
    "umap_fit_5.fit(tb_sca_cp)\n",
    "\n",
    "umap_fit_20 = umap.UMAP(n_neighbors = 20, n_components=2, random_state=42, densmap = True)\n",
    "umap_fit_20.fit(tb_sca_cp)\n",
    "\n",
    "umap_fit_50 = umap.UMAP(n_neighbors = 50, n_components=2, random_state=42, densmap = True)\n",
    "umap_fit_50.fit(tb_sca_cp)\n",
    "\n",
    "tb_umap_5 = pd.DataFrame(\n",
    "    umap_fit_5.transform(tb_sca_cp),\n",
    "    columns=[\"UM_0\", \"UM_1\"],\n",
    "    index = tb_sca_cp.index\n",
    ")\n",
    "tb_umap_20 = pd.DataFrame(\n",
    "    umap_fit_20.transform(tb_sca_cp),\n",
    "    columns=[\"UM_0\", \"UM_1\"],\n",
    "    index = tb_sca_cp.index\n",
    ")\n",
    "\n",
    "tb_umap_50 = pd.DataFrame(\n",
    "    umap_fit_50.transform(tb_sca_cp),\n",
    "    columns=[\"UM_0\", \"UM_1\"],\n",
    "    index = tb_sca_cp.index\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "sns.scatterplot(data=tb_umap_5, x=\"UM_0\", y=\"UM_1\", s = 10, ax = ax[0])\n",
    "ax[0].set_title(\"DENSMAP with 5 Neighbors\")\n",
    "sns.scatterplot(data=tb_umap_20, x=\"UM_0\", y=\"UM_1\", s = 10, ax = ax[1])\n",
    "ax[1].set_title(\"DENSMAP with 20 Neighbors\")\n",
    "sns.scatterplot(data=tb_umap_50, x=\"UM_0\", y=\"UM_1\", s = 10, ax = ax[2])\n",
    "ax[2].set_title(\"DENSMAP with 50 Neighbors\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "014f4a4a5af8f0104b12c029e500f4146d6d785e8cf714d2a35b7a9514230cd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
