{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de Classificação II\n",
    "\n",
    "Vamos avançar nossos estudos sobre métodos de classificação analisando dois novos algoritmos (o *Perceptron de Múltiplas Camadas* e os *Modelos de Ensemble*). Além disso teremos o primeiro contato com os conceitos de *underfitting* e *overfitting*, e como esses conceitos se relacionam com a **complexidade** dos modelos de ML.\n",
    "\n",
    "Primeiro, vamos carregar nosso dataset de exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_cov = pd.read_parquet(\"data/covtype.parquet\")\n",
    "tb_cov.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de Dados de Cobertura Florestal dos EUA\n",
    "\n",
    "Este conjunto de dados contém informações sobre a cobertura florestal de diferentes lugares dos Estados Unidos. Além da variável target, que é o tipo de árvore predominante na área, também temos informações sobre a região, como:\n",
    "\n",
    "- Altitude\n",
    "- Inclinação do terreno\n",
    "- Distância até a água mais próxima\n",
    "\n",
    "Essas informações foram obtidas a partir do processamento de imagens de satélite.\n",
    "\n",
    "### Análise da Variável Target\n",
    "\n",
    "A variável target é o tipo de árvore predominante na área:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_cov[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "sns.countplot(data=tb_cov, x=\"target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver no gráfico acima, temos um total de 7 classes de árvores. A classe predominante é a segunda no gráfico, que corresponde à árvores do tipo *Lodgepole Pine*.\n",
    "\n",
    "Esse tipo de fenômeno é comum em problemas de classificação (como no exemplo de fraudes em cartão de crédito): **nossas classe estão desbalanceadas**. Isso significa que temos muito mais exemplos de uma classe do que de outras. No caso de fraudes, temos muito mais transações legítimas do que fraudulentas. No caso de árvores, temos muito mais *Lodgepole Pine* e *Spruce/Fir* do que o resto.\n",
    "\n",
    "O desbalanço de classes pode ser um problema para alguns algoritmos de classificação. Por exemplo, se tivermos um algoritmo que sempre chuta a classe mais frequente, ele terá uma acurácia de 50% no nosso dataset de árvores. Isso porque 50% das árvores são *Lodgepole Pine*. Mais adiante veremos como podemos tratar esse problema. Primeiro, vamos usar um `LabelEncoder` para converter nosso target de `strings` para números de forma estruturada:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(tb_cov[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utilização de um `LabelEncoder` garante que as categorias sejam sempre ordenadas da mesma forma (a primeira classe é sempre 0, a segunda é sempre 1, etc).\n",
    "\n",
    "### Análise dos Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_cov.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos ao todo 12 features contendo informações sobre a localização, o solo e o clima de cada área. Entre essas, 2 são categóricas e 10 são numéricas. Vamos focar nossa análise exploratória em dois eixos: avaliar a colinearidade e distribuição de nossos variáveis numéricas.\n",
    "\n",
    "#### Colinearidade\n",
    "\n",
    "Vamos analisar a colinearidade entre nossas variáveis numéricas. Para isso, vamos utilizar a matriz de correlação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(tb_cov.corr(numeric_only=True), vmin=-1, vmax=1, cmap=\"Spectral\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `sns.clustermap()` nos permite visualizar grupos de variáveis correlatas (diretamente ou indiretamente). Na sua avaliação, temos grupos de variáveis correlatas? Como podemos tratar essa colinearidade sem descartar variáveis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribuição\n",
    "\n",
    "Como vimos quando trabalhamos no problema dos diamantes, variáveis positivas com distribuição muito assimétrica podem ser transformadas para melhorar o desempenho de alguns algoritmos. Vamos avaliar a distribuição de nossas variáveis numéricas utilizando histogramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_melt = tb_cov.select_dtypes(include=np.number).melt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data=tb_melt,\n",
    "    x=\"value\",\n",
    "    col=\"variable\",\n",
    "    kind=\"kde\",\n",
    "    col_wrap=3,\n",
    "    facet_kws={\"sharex\": False, \"sharey\": False},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poderíamos fazer a conversão de variáveis manualmente e inicializar nossos normalizadores, PCAs, Encoders separadamente. Mas o `sklearn` nos permite criar um pipeline de transformação de dados, que pode ser aplicado em qualquer conjunto de dados. Vamos criar um pipeline para transformar nossos dados e aplicá-lo em nosso dataset.\n",
    "\n",
    "## Utilizando Pipelines\n",
    "\n",
    "Pipelines são uma forma de automatizar o processo de transformação de dados. Eles são especialmente úteis quando temos muitas transformações a serem feitas, ou quando queremos aplicar a mesma transformação em vários conjuntos de dados diferentes (por exemplo, em um conjunto de treino e em um conjunto de teste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "]\n",
    "cat_vars = [\"Wilderness_Area\", \"Soil_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tb_cov[num_vars + cat_vars]\n",
    "y = le.transform(tb_cov[\"target\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos desenhar o fluxo de transformações que serão executadas sobre nossas *features* de acordo com sua natureza (categórica ou contínua):\n",
    "\n",
    "1. **Variáveis Contínuas**:\n",
    "    1. Transformação Logarítmica (tratar assimetria);\n",
    "    1. Normalização (etapa básica de pré-processamento);\n",
    "    1. PCA (remover colinearidade)\n",
    "1. **Variáveis Categóricas**:\n",
    "    1. One-Hot Encoding (transformar em variáveis binárias dummies)\n",
    "\n",
    "Vamos criar um pipeline para cada tipo de transformação e depois juntá-los em um pipeline único."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um pipeline nada mais é que **uma sequência de transformações e modelos** que são executados em sequencia. Para criar um pipeline, precisamos de uma lista de tuplas, onde cada tupla contém o nome do passo e o objeto que será executado. Por exemplo, para criar um pipeline que transforma nossas variáveis contínuas, precisamos de uma lista de tuplas com os seguintes passos:\n",
    "\n",
    "1. `PowerTransformer()`: transformação logarítmica;\n",
    "1. `StandardScaler()`: normalização;\n",
    "1. `PCA()`: redução de dimensionalidade e colinearidade.\n",
    "\n",
    "Para isso, precisamos inicilizar cada um desses objetos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "sca = StandardScaler()\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, precisamos criar uma lista de tuplas com o nome de cada passo e o objeto que será executado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_etapas = [(\"POWER_TRANS\", pt), (\"STD_SCALER\", sca), (\"PCA\", pca)]\n",
    "num_pipeline = Pipeline(lista_etapas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto! Vamos textar nosso `pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline.fit(X_train[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline.transform(X_train[num_vars])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfeito! Agora vamos criar um pipeline para nossas variáveis categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "cat_pipeline = Pipeline([(\"ONE_HOT\", ohe)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline.fit(X_train[cat_vars])\n",
    "cat_pipeline.transform(X_train[cat_vars])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simples! Agora vamos juntar os dois pipelines em um único pipeline. Para isso, vamos utilizar o `ColumnTransformer` - um objeto que nos permite aplicar transformações diferentes em colunas diferentes. Esse objeto recebe como argumento uma lista de uplas onde cada upla tem o nome da etapa, o objeto que será executado e uma lista de nomes de colunas que serão transformadas por essa etapa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipeline_preprocessamento = [\n",
    "    (\"NUMERICOS\", num_pipeline, num_vars),\n",
    "    (\"CATEGORICOS\", cat_pipeline, cat_vars),\n",
    "]\n",
    "data_prep_pipeline = ColumnTransformer(pipeline_preprocessamento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipeline.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipeline.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É uma boa prática guardar todas as etapas de nosso pipeline em uma única célula, facilitando a adição, troca e remoção de etapas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Numérico\n",
    "pt = PowerTransformer()\n",
    "sca = StandardScaler()\n",
    "pca = PCA()\n",
    "lista_etapas = [(\"POWER_TRANS\", pt), (\"STD_SCALER\", sca), (\"PCA\", pca)]\n",
    "num_pipeline = Pipeline(lista_etapas)\n",
    "\n",
    "# Pipeline Categórico\n",
    "ohe = OneHotEncoder()\n",
    "cat_pipeline = Pipeline([(\"ONE_HOT\", ohe)])\n",
    "\n",
    "# Pipeline de Preprocessamento\n",
    "pipeline_preprocessamento = [\n",
    "    (\"NUMERICOS\", num_pipeline, num_vars),\n",
    "    (\"CATEGORICOS\", cat_pipeline, cat_vars),\n",
    "]\n",
    "data_prep_pipeline = ColumnTransformer(pipeline_preprocessamento)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além de etapas de pré-processamento, podemos adicionar modelos ao nosso pipeline. Vamos adicionar um modelo de regressão logística ao nosso pipeline, o qual usaremos como baseline de erro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "lm_pipeline = Pipeline([(\"PREP\", data_prep_pipeline), (\"LM\", lm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando inserimos um modelo no final de nosso pipeline devemos incluir nossa variável target ao utilizar o método `.fit()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora só precisamos avaliar o erro desse modelo...\n",
    "\n",
    "## Erro Multi-Classe\n",
    "\n",
    "Muitos das medidas de erro que vimos na última aula dependem do conceito de **Falso Positivo/Negativo** e **Verdadeiro Positivo/Negativo**. Esses conceitos são fáceis de entender quando temos apenas duas classes, mas como podemos aplicá-los em problemas com mais de duas classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lm = lm_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "cf = confusion_matrix(y_test, y_pred_lm, normalize=\"true\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf, display_labels=le.classes_)\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos entender agora como podemos calcular o erro de um modelo de classificação multi-classe.\n",
    "\n",
    "### Acurácia (do jeito errado)\n",
    "\n",
    "Vamos começar calculando a **acurácia média**: o número de acertos totais dividido pelo número de exemplos totais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "print(f\"Acurácia de {np.round(accuracy_score(y_test, y_pred_lm), 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O score acima tem um problema: ele não leva em consideração o desbalanceamento de classes, nesse exemplo agravado pela natureza multi-classe do problema. Perdemos toda visibilidade que nosso modelo, em algumas classes, tem quase 100% de erro!\n",
    "\n",
    "Esse problema ocorrerá com **todas** as funções - elas serão resultados médios, que muitas vezes podem ocultar o que está acontecendo em nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "\n",
    "A função `classification_report()` nos dá uma visão mais detalhada do desempenho de nosso modelo. Ela nos dá a precisão, recall e f1-score para cada classe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_lm, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora a visão acima seja bem detalhada, ela sofre do mesmo problema que a matriz de confusão: não conseguimos comparar de forma direta o desempenho de cada modelo. Para isso precisaremos utilizar o F1-Score (e Precision/Recall).\n",
    "\n",
    "Nesse caso teremos o mesmo problema que na acurácia: estaremos resumindo, de alguma forma, a performance de nosso modelo à um único número. Essa simplificação é feita, tradicionalmente, de duas formas:\n",
    "\n",
    "1. **Weighted**: calcula o F1-Score para cada classe e tira a média, ponderando esta média pelo tamanho de cada classe.\n",
    "2. **Macro**: calcula o F1-Score para cada classe e tira a média, sem ponderar esta média pelo tamanho de cada classe.\n",
    "\n",
    "Podemos ver que essas duas formas de medir o erro são antagônicas: a primeira ignora o desbalanceamento de classes, enquanto a segunda dá importância igual à todas as classes. Qual delas devemos utilizar? Depende! Se prever **classes minoritárias é importante** (previsão de eventos raros, como fraudes ou incidência de doenças raras) devemos utilizar o **F1-Score Macro**. Se **não for crítico o desempenho em classes minoritárias**, por exemplo em um modelo de categorização da busca do cliente, podemos utilizar o **F1-Score Weighted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred_lm, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Acurácia de {np.round(accuracy_score(y_test, y_pred_lm), 2)}\")\n",
    "print(f\"F1-Score Macro de {np.round(f1_score(y_test, y_pred_lm, average='macro'), 2)}\")\n",
    "print(\n",
    "    f\"F1-Score Ponderado de {np.round(f1_score(y_test, y_pred_lm, average='weighted'), 2)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretando nossa Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_eval = X_train.copy()\n",
    "probabilidades = lm_pipeline.predict_proba(X_train)\n",
    "for i, tree in enumerate(le.classes_):\n",
    "    tb_eval[f\"prob_lm_{tree}\"] = probabilidades[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    tb_eval.corr(numeric_only=True),\n",
    "    vmin = -1, vmax = 1, center = 0, cmap = \"Spectral\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data = tb_eval,\n",
    "    x = \"Elevation\",\n",
    "    y = \"prob_lm_Spruce/Fir\",\n",
    "    s= 1, alpha = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nosso modelo tem muitas variáveis, embora exista uma relação clara entre a elevação e a probabilidade da cobertura ser de pinheiros-alemães, não conseguimos visualizar diretamente essa relação. Vamos construir uma base de dados específica para analisar o efeito marginal desta variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_eval = pd.DataFrame()\n",
    "tb_eval[\"Elevation\"] = np.linspace(X_train[\"Elevation\"].min(), X_train[\"Elevation\"].max(), 1000)\n",
    "for column in X_train.select_dtypes(include=\"number\").columns:\n",
    "    if column != \"Elevation\":\n",
    "        tb_eval[column] = X_train[column].mean()\n",
    "for column in X_train.select_dtypes(exclude=\"number\").columns:\n",
    "    tb_eval[column] = X_train[column].mode()[0]\n",
    "tb_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades = lm_pipeline.predict_proba(tb_eval)\n",
    "for i, tree in enumerate(le.classes_):\n",
    "    tb_eval[f\"prob_lm_{tree}\"] = probabilidades[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    data = tb_eval,\n",
    "    x = \"Elevation\",\n",
    "    y = \"prob_lm_Spruce/Fir\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais\n",
    "\n",
    "Redes neurais são uma classe de modelo preditivo que surgiu a partir da pesquisa sobre o funcionamento das células neuronais do cérebro - desenvolvida inicialmente por McCulloh e Pitts na década de 40. O modelo mais comum de rede neural, o **perceptron de múltiplas camadas (MLP)** foi desenvolvido em 1958 pelo psicológo Rosenblatt.\n",
    "\n",
    "Os **MLPs** são caracterizados por dois atributos fundamentais:\n",
    "\n",
    "* Número de neurônios por camada;\n",
    "* Função de Ativação.\n",
    "\n",
    "![MLP](images/multipercep.jpg)\n",
    "\n",
    "Vamos criar um MLP para resolver nosso problema de classificação, variando o tamanho de nossa rede neural e analisando o resultado de nossas previsões:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4, 4), activation=\"relu\", random_state=10)\n",
    "mlp_pipeline = Pipeline([(\"PREP\", data_prep_pipeline), (\"MLP\", mlp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos avaliar nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = mlp_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_nn, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos nos lembrar dos resultados da regressão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lm, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades = mlp_pipeline.predict_proba(tb_eval)\n",
    "for i, tree in enumerate(le.classes_):\n",
    "    tb_eval[f\"prob_nn_{tree}\"] = probabilidades[:,i]\n",
    "    \n",
    "sns.lineplot(\n",
    "    data = tb_eval,\n",
    "    x = \"Elevation\",\n",
    "    y = \"prob_nn_Spruce/Fir\",\n",
    "    label = \"MLP de (4, 4)\"\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data = tb_eval,\n",
    "    x = \"Elevation\",\n",
    "    y = \"prob_lm_Spruce/Fir\",\n",
    "    label = \"Regresão Logística\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, pelo menos neste efeito, uma rede neural simples se comporta de maneira bem semelhante à nossa regressão. Vamos aumentar o número de neurônios em nossa rede neural e ver o que acontece:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30, 30, 30), activation=\"relu\", random_state=10)\n",
    "mlp_pipeline = Pipeline([(\"PREP\", data_prep_pipeline), (\"MLP\", mlp)])\n",
    "mlp_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades = mlp_pipeline.predict_proba(tb_eval)\n",
    "for i, tree in enumerate(le.classes_):\n",
    "    tb_eval[f\"prob_nn2_{tree}\"] = probabilidades[:,i]\n",
    "    \n",
    "sns.lineplot(\n",
    "    data = tb_eval,\n",
    "    x = \"Elevation\",\n",
    "    y = \"prob_nn_Spruce/Fir\",\n",
    "    label = \"MLP de (4, 4)\"\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data = tb_eval,\n",
    "    x = \"Elevation\",\n",
    "    y = \"prob_nn2_Spruce/Fir\",\n",
    "    label = \"MLP de (30, 30, 30)\"\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data = tb_eval,\n",
    "    x = \"Elevation\",\n",
    "    y = \"prob_lm_Spruce/Fir\",\n",
    "    label = \"Regresão Logística\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente a rede complexa é muito menos linear que nossos dois outros modelos! Vamos avaliar o erro de nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn2 = mlp_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_nn2, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma melhoria significativa - especialmente nas classes minoritárias! Como todos os algoritmos de ML, redes neurais tem muitos hiperparâmetros que podem ser ajustados para melhorar o desempenho do modelo. Os principais são:\n",
    "\n",
    "1. **Topologia da rede** - `hidden_layer_sizes`: número de camadas e número de neurônios por camada (em um MLP);\n",
    "1. **Função de Ativação** - `activation`: função que determina o valor de saída de cada neurônio (hoje em dia quase nunca utilizamos funções diferentes da **ReLU**);\n",
    "1. **Taxa de Aprendizagem** - `learning_rate_init`: o *learning rate* determina o quão agressiva a rede neural tenta se ajustar aos dados em cada iteração do algoritmo de otimização, padrão entre 0.00001 e 1;\n",
    "1. **Número de Iterações** - `max_iter`: número de iterações do algoritmo de otimização (quantas vezes seu dataset completo passa pela rede).\n",
    "\n",
    "Vamos ver como podemos alterar o `max_iter` buscando um ponto ótimo entre precisão e tempo de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "for i in range(5, 101, 10):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(30, 30, 30), activation=\"relu\", random_state=10, max_iter = i)\n",
    "    mlp_pipeline = Pipeline([(\"PREP\", data_prep_pipeline), (\"MLP\", mlp)])\n",
    "    mlp_pipeline.fit(X_train, y_train)\n",
    "    y_pred_test = mlp_pipeline.predict(X_test)\n",
    "    y_pred_train = mlp_pipeline.predict(X_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train, average=\"macro\")\n",
    "    f1_test = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "    f1_list.append([i, f1_train, f1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_f1 = pd.DataFrame(f1_list, columns = [\"max_iter\", \"f1_train\", \"f1_test\"])\n",
    "sns.lineplot(data = tb_f1, x = \"max_iter\", y = \"f1_train\", label = \"Treino\")\n",
    "sns.lineplot(data = tb_f1, x = \"max_iter\", y = \"f1_test\", label = \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
