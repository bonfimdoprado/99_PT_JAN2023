{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando e Exportando Dados\n",
    "\n",
    "Na última aula tivemos nosso primeiro contato com a função `pd.read_csv()` - a qual utilizamos para carregar o arquivo de veículos (um arquivo **.csv**) para um DataFrame.\n",
    "\n",
    "Hoje veremos como carregar diferentes tipos de arquivo **.csv** através dessa função. Além disso veremos como carregar diferentes tipos de arquivo utilizando a biblioteca Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:05:31.618273Z",
     "start_time": "2021-12-04T12:05:31.228262Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lermos arquivos **.xlsx** do Excel precisamos instalar a biblioteca `openpyxl` - podemos verificar se ela foi instalando importando o módulo `xlrd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:05:30.733368Z",
     "start_time": "2021-12-04T12:05:30.705470Z"
    }
   },
   "outputs": [],
   "source": [
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O formato **parquet** tem se tornado ubíquo no universo de dados. Sua performance é superior aos arquivos *.csv*, tanto no tamanho ocupado pela tabela quanto na velocidade de leitura.\n",
    "\n",
    "Para lermos arquivos parquet precisaremos instalar o módulo `fastparquet`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastparquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando arquivos delimitados\n",
    "\n",
    "Arquivos delimitados são arquivos texto que utilizam um caráctere especial para separar as colunas. A extensão mais comum para este tipo de arquivo é o **.csv**, mas muitas vezes veremos outras extensões como **.txt** ou **.tsv**.\n",
    "\n",
    "A extensão em si não é muito importante: o importante é sabermos que o arquivo é um arquivo de texto, e como ele está estruturado. Os tipos mais comuns de separadores sáo:\n",
    "    \n",
    "**-- comma separated file --**\n",
    "\n",
    "    name,year,value\n",
    "    Andre,2020,100\n",
    "    Fernanda,1900,1\n",
    "    \n",
    "**-- tab separated file --**\n",
    "\n",
    "    name    year    value\n",
    "    Andre    2020    100\n",
    "    Fernanda    1900    1\n",
    "    \n",
    "**-- tab separated file (another way) --**\n",
    "\n",
    "    name\\tyear\\tvalue\n",
    "    Andre\\t2020\\t100\n",
    "    Fernanda\\t1900\\t1\n",
    "    \n",
    "**-- hash separated file --**\n",
    "\n",
    "    name#year#value\n",
    "    Andre#2020#100\n",
    "    Fernanda#1900#1\n",
    "\n",
    "**-- pipe separated file --**\n",
    "\n",
    "    name|year|value\n",
    "    Andre|2020|100\n",
    "    Fernanda|1900|1\n",
    "\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descobrindo a Estrutura do Arquivo\n",
    "\n",
    "Muitas vezes não saberemos de antemão qual a estrutura do arquivo que precisamos ler. Caso o arquivo seja pequeno (< 10mb) podemos abri-lo no Notepad ou em algum outro editor de texto simples (Notepad++, SublimeText, Vi) e ver a estrutura diretamente.\n",
    "\n",
    "Infelizmente muitas vezes lidamos com arquivos tão grandes que é quase impossível abri-los nestes editores. Para investigar a estrutura desses arquivos podemos utilizar o próprio Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:04:38.694940Z",
     "start_time": "2021-12-04T12:04:38.688955Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('data/dados_veiculos.csv', 'rb')\n",
    "file_lines = file.readlines(1000)\n",
    "for line in file_lines:\n",
    "    print(line.decode('utf-8'))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dados_veiculos.csv', 'rb') as file:\n",
    "    file_lines = file.readlines(1000)\n",
    "    for line in file_lines:\n",
    "        print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos prestar atenção em **três pontos chaves**:\n",
    "\n",
    "1. A primeira linha do arquivo contém um cabeçalho?\n",
    "1. Qual caráctere está sendo utilizado para separar as colunas?\n",
    "1. Qual caráctere é utilizado como separador decimal?\n",
    "1. Os diacríticos estão sendo lidos corretamente?\n",
    "\n",
    "### CSV (Comma Separated Values)\n",
    "\n",
    "Quando os arquivos que estamos importando utilizam a `,` como separador de colunas ele é chamado de CSV (comma separated values). Vamos classificar nosso arquivo `dados_veiculos.csv` segundo os nossos 4 critérios:\n",
    "\n",
    "1. Cabeçalho:\n",
    "1. Caráctere Separador:\n",
    "1. Caráctere Decimal:\n",
    "1. Diácriticos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:05:34.890672Z",
     "start_time": "2021-12-04T12:05:34.783957Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('data/dados_veiculos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `pd.read_csv()` não está guardando o DataFrame em nenhuma variável: se quisermos utiliza-lo posteriormente tenho que guarda-lo em uma variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:05:37.656697Z",
     "start_time": "2021-12-04T12:05:37.577466Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_veic = pd.read_csv('data/dados_veiculos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:05:45.283025Z",
     "start_time": "2021-12-04T12:05:45.251114Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_veic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSVs de `;`\n",
    "\n",
    "Muitos países utilizam a `,` como separador decimal - muitas vezes arquivos CSV desses países utilizarão o `;` como separador de colunas (para não gerar confusão com os números decimais).\n",
    "\n",
    "Vamos fazer a nossa avaliação de um novo arquivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv('data/dados_veiculos_semi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dados_veiculos_semi.csv', 'rb') as file:\n",
    "    file_lines = file.readlines(1000)\n",
    "    for line in file_lines:\n",
    "        print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O comportamento padrão do Pandas é utilizar:\n",
    "\n",
    "1. Primeira linha como cabeçalho;\n",
    "1. `,` como separador;\n",
    "1. `.` como decimal.\n",
    "\n",
    "Para alterar o separador de colunas e de decimais precisamos especificar estes carácteres diretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/dados_veiculos_semi.csv', \n",
    "            sep = \";\", decimal = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquivos TSV (Tab-Separated Values)\n",
    "\n",
    "Alguns arquivos utilizam o `\\t`, ou **tab**, como separador de valores. Vamos ver como carregar arquivos deste tipo utilizando a `pd.read_csv()`.\n",
    "\n",
    "O arquivo abaixo, além de ser separado por **tabs**, contém diacríticos (acentos, cedilhas, etc...). Quando um arquivo contém carácters não-ASCII (como acentos) precisamos estar atentos ao **encoding** do arquivo - como ele representa esses carácteres diferentes.\n",
    "\n",
    "Em geral, os arquivos estarão **encodados** em `UTF-8` (a maior parte dos arquivos) ou em `latin-1` (arquivos mais antigos, principalmente de sistemas Windows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:06:33.284013Z",
     "start_time": "2021-12-04T12:06:33.270051Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/tb_empenho_cnpj_osc.txt', 'rb') as file:\n",
    "    file_lines = file.readlines(1000)\n",
    "    for line in file_lines:\n",
    "        print(line.decode('latin-1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tentarmos carregar um arquivo sem especificar o **encoding** correto poderemos ter um erro, ou então carregar os diacríticos de maneira errada!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:06:56.630388Z",
     "start_time": "2021-12-04T12:06:56.592486Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('data/tb_empenho_cnpj_osc.txt', \n",
    "            sep = '\\t', \n",
    "            decimal = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:07:08.237791Z",
     "start_time": "2021-12-04T12:07:08.154015Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_oscsp = pd.read_csv('data/tb_empenho_cnpj_osc.txt', \n",
    "                       sep = '\\t', \n",
    "                       decimal = ',', \n",
    "                       encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:07:18.022621Z",
     "start_time": "2021-12-04T12:07:17.998685Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_oscsp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_oscsp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquivos separados por `|`\n",
    "\n",
    "Outro separador comum é o `|` (**pipe**). Vamos carregar um arquivo com este separador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:07:54.167780Z",
     "start_time": "2021-12-04T12:07:54.143823Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/eletricidade_india.csv', 'rb') as file:\n",
    "    file_lines = file.readlines(10000)\n",
    "    for line in file_lines:\n",
    "        print(line.decode('latin-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:08:13.114341Z",
     "start_time": "2021-12-04T12:08:13.092401Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_elecindia = pd.read_csv('data/eletricidade_india.csv', \n",
    "                           sep = '|',\n",
    "                           decimal = '.')\n",
    "tb_elecindia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_elecindia.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar os argumento `parse_dates` e `infer_datetime_format` para carregar corretamente o campo de data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:08:06.576698Z",
     "start_time": "2021-12-04T12:08:06.532816Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_elecindia = pd.read_csv('data/eletricidade_india.csv', \n",
    "                           sep = '|', \n",
    "                           decimal = '.',\n",
    "                           parse_dates = ['Date'], \n",
    "                           infer_datetime_format = True)\n",
    "tb_elecindia.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_elecindia['Date'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando arquivos de URLs\n",
    "\n",
    "Muitas plataformas disponibilizam dados através de URLs - caso esses dados sejam arquivos delimitados, podemos utilizar a `pd.read_csv()` para importa-los diretamente.\n",
    "\n",
    "Como não poderemos ler o arquivo via `.readlines()` precisamos buscar na plataforma a especificação do arquivo.\n",
    "\n",
    "Exemplo: https://datasets.imdbws.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:08:58.841431Z",
     "start_time": "2021-12-04T12:08:57.591503Z"
    }
   },
   "outputs": [],
   "source": [
    "url_csv = 'https://datasets.imdbws.com/title.ratings.tsv.gz'\n",
    "tb_imdbratings = pd.read_csv(url_csv, \n",
    "                             sep = '\\t', \n",
    "                             encoding = 'utf-8', \n",
    "                             na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando arquivos Excel\n",
    "\n",
    "Podemos utilizar a função `pd.read_excel()` para ler arquivos Excel diretamente (sem precisar salvá-los como `.csv`).\n",
    "\n",
    "Arquivos Excel tem o tipo da coluna determinado dentro do programa (numérico, data, string) e o Pandas importará essas definições. Além disso, podem conter mais que uma *aba*: para especificar qual aba queremos abrir utilizaremos o parâmetro `sheet_name` caso necessário.\n",
    "\n",
    "Fonte: https://www.kaggle.com/sanjeetsinghnaik/most-expensive-footballers-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:09:08.348743Z",
     "start_time": "2021-12-04T12:09:07.798166Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_futebol = pd.read_excel('data/Dados Jogadores Futebol.xlsx')\n",
    "tb_futebol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_futebol.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Google Sheets\n",
    "\n",
    "Podemos importar planilhas do Google Sheet diretamente utilizando um *hack* simples através do URL de compartilhamento:\n",
    "* substituir `/edit?usp=sharing` por `/export?format=csv`\n",
    "    \n",
    "(https://stackoverflow.com/questions/19611729/getting-google-spreadsheet-csv-into-a-pandas-dataframe)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:09:37.374140Z",
     "start_time": "2021-12-04T12:09:37.358183Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_from_gsheets(spreadsheet):\n",
    "    \"\"\"\n",
    "    Transform url into csv \n",
    "    \"\"\"\n",
    "    working_spreadsheet = spreadsheet.replace('/edit?usp=sharing','/export?format=csv')\n",
    "    \n",
    "    return pd.read_csv(working_spreadsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:09:38.929504Z",
     "start_time": "2021-12-04T12:09:37.884764Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_fortune1000 = read_from_gsheets('https://docs.google.com/spreadsheets/d/1qfz8GgZbuNMI913YaCIcYHmMCHB1FCCnOLnk907ZwPM/edit?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:09:39.457223Z",
     "start_time": "2021-12-04T12:09:39.433286Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_fortune1000.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando arquivos JSON\n",
    "\n",
    "Arquivos JSON são uma forma comum de aplicações Web transferirem dados. Eles se parecem muito com dicionários e listas: são estruturas com `chaves` e `valores`:\n",
    "\n",
    "JSON 1:\n",
    "```json\n",
    "{ \"name\":\"John\", \"age\":30, \"car\":null }\n",
    "```\n",
    "\n",
    "JSON 2: \n",
    "```json\n",
    "{\"students\":[\n",
    "   {\"name\":\"Andre\", \"age\":23, \"state\":\"SP\"},\n",
    "   {\"name\":\"Rodrigo\", \"age\":28, \"state\":\"SP\"},\n",
    "   {\"name\":\"Raiana\", \"age\":32, \"state\":\"DF\"},\n",
    "   {\"name\":\"Tieko\", \"age\":28, \"state\":\"BA\"}\n",
    "]}\n",
    "```\n",
    "\n",
    "Orientação de `records`, onde o JSON é uma lista de dicionários. Cada dicionário desta lista é uma linha da nossa tabela\n",
    "```python\n",
    "[\n",
    "    {\"coluna1\" : valor, \"coluna2\" : valor},\n",
    "    {\"coluna1\" : valor, \"coluna2\" : valor},\n",
    "    {\"coluna1\" : valor, \"coluna2\" : valor},\n",
    "    {\"coluna1\" : valor, \"coluna2\" : valor},\n",
    "    {\"coluna1\" : valor, \"coluna2\" : valor},\n",
    "]\n",
    "```\n",
    "\n",
    "Orientação de `index`, onde o JSON é um dicionário. Cada chave desse dicionário é uma linha de nossa tabela e guarda um outro dicionário com os dados da tabela referente àquela linha.\n",
    "```python\n",
    "{\n",
    "    linha_1 : {\"coluna1\" : valor, \"coluna2\" : valor},\n",
    "    linha_2 : {\"coluna1\" : valor, \"coluna2\" : valor},\n",
    "    linha_3 : {\"coluna1\" : valor, \"coluna2\" : valor},\n",
    "    linha_4 : {\"coluna1\" : valor, \"coluna2\" : valor},\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:10:02.141767Z",
     "start_time": "2021-12-04T12:10:02.061968Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_crypto = pd.read_json('data/crypto_data_records.json', orient = 'records') # orient informa a orientação do JSO\n",
    "tb_crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:10:50.281700Z",
     "start_time": "2021-12-04T12:10:50.206884Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_crypto = pd.read_json('data/crypto_data_index.json', orient = 'index') # orient informa a orientação do JSO\n",
    "tb_crypto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando arquivos Parquet\n",
    "\n",
    "Os arquivos **parquet** são como os arquivos *.csv* e são utilizados para armazenar dados tabulares. Este formato foi desenvolvido pela fundação **Apache** para tornar o armazenamento e leitura de dados tabulares mais eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_crypto_parquet = pd.read_parquet('data/tb_crypto.parquet')\n",
    "tb_crypto_parquet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo arquivos de uma pasta\n",
    "\n",
    "Até agora vimos como abrir diferentes formatos de arquivo, sempre um por vez. Uma tarefa muito comum que encontraremos ao longo do curso (e da carreira) é importar diversos arquivos, com a mesma formatação, de uma vez só.\n",
    "\n",
    "Para fazer isso utilizaremos a função `os.listdir()` para construir uma lista de nomes de arquivo e então carregaremos eles um por um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "lista_arquivos = os.listdir('data/dados_censo/')\n",
    "print(lista_arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T12:11:28.738817Z",
     "start_time": "2021-12-04T12:11:28.722833Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/dados_censo/Basico_BA.csv', 'rb') as file:\n",
    "    file_lines = file.readlines(1000)\n",
    "    for line in file_lines:\n",
    "        print(line.decode('latin-1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T11:50:55.879208Z",
     "start_time": "2021-12-04T11:50:55.137193Z"
    }
   },
   "outputs": [],
   "source": [
    "lista_df_censo = []\n",
    "for file in os.listdir('data/dados_censo/'):\n",
    "    file_path = 'data/dados_censo/' + file\n",
    "    lista_df_censo.append(pd.read_csv(file_path, sep = \";\", decimal = \",\", encoding = \"latin-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T11:51:01.777118Z",
     "start_time": "2021-12-04T11:51:01.734212Z"
    }
   },
   "outputs": [],
   "source": [
    "lista_df_censo[0].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportando arquivos\n",
    "\n",
    "Além de importar arquivos como DataFrames, a Pandas nos permite exportar DataFrames para arquivos.\n",
    "\n",
    "### Exportando arquivos CSV\n",
    "\n",
    "Para exportar um DataFrame para um arquivo `.csv` utilizaremos o método `.to_csv()`. Este método recebe argumentos muito semelhantes à função `pd.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T11:53:04.642867Z",
     "start_time": "2021-12-04T11:53:03.249329Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_censo.to_csv('data/tb_censo.csv', \n",
    "                         sep = \";\", \n",
    "                         decimal = \",\", \n",
    "                         encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: Se não utilizarmos o argumento `index=False`, o método criará uma coluna sem nome, na posição da primeira coluna, com os índices do DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T11:53:04.658828Z",
     "start_time": "2021-12-04T11:53:04.643841Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/tb_censo.csv', 'rb') as file:\n",
    "    file_lines = file.readlines(1000)\n",
    "    for line in file_lines:\n",
    "        print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alterando o separador\n",
    "\n",
    "Podemos utilizar a biblioteca Pandas para reformartar arquivos separados: carregamos utilizando um padrão e escrevemos utilizando outro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T11:54:04.881962Z",
     "start_time": "2021-12-04T11:54:04.129943Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_elecindia.to_csv('data/tb_elecindia_corrig.csv', \n",
    "                    sep = \",\", \n",
    "                    decimal = \".\", \n",
    "                    encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T11:54:04.896896Z",
     "start_time": "2021-12-04T11:54:04.883955Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/tb_elecindia_corrig.csv', 'rb') as file:\n",
    "    file_lines = file.readlines(1000)\n",
    "    for line in file_lines:\n",
    "        print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando para Parquet\n",
    "\n",
    "Vamos utilizar o método `.to_parquet()` para exportar os nossos dados dos gastos com OSCs na Prefeitura de São Paulo para um arquivo **parquet** e comparar o tamanho deste arquivo com o CSV que geramos acima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_oscsp.to_parquet('data/tb_empenho_cnpj_osc.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportanto para Excel\n",
    "\n",
    "Podemos utilizar o método `.to_excel()` para exportar um DataFrame para uma planilha de Excel. O único atributo importante é o `sheet_name`, onde determinamos o nome da aba na qual os dados serão escritos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T11:55:48.170817Z",
     "start_time": "2021-12-04T11:55:26.821754Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_crypto.to_excel('data/Tabela Crypto.xlsx', sheet_name = 'dados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando para JSON\n",
    "\n",
    "Para exportamos para JSON temos diferentes opções de orientação, acessadas através do parâmetro `orient`.\n",
    "\n",
    "`'split'`: Dicionário contendo índices, colunas e dados\n",
    "\n",
    "`'index'`: Dicionários de dicionários contendo {index:{column:value}}.\n",
    "\n",
    "`'columns'`: Dicionários de dicionários contendo{column:{index:value}}\n",
    "\n",
    "`'values'`: Lista de listas, onde cada sub-lista contém uma linha de nossa tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T17:12:43.703386Z",
     "start_time": "2020-07-30T17:12:43.686386Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_oscsp.to_json('tb_oscsp.json', orient = 'index')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "249px",
    "width": "337px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.813px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "vscode": {
   "interpreter": {
    "hash": "014f4a4a5af8f0104b12c029e500f4146d6d785e8cf714d2a35b7a9514230cd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
